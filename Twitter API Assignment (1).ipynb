{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a362512a",
   "metadata": {},
   "source": [
    "# Twitter API\n",
    "By: Gloria Sladek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce43716",
   "metadata": {},
   "source": [
    "Using Twitter Data I hope to answer the question of how artists are using twitter as a platform. More specifically I would like to identify the types of art being posted: Ie traditional vs. Digital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcebd2e",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dfbb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c370b32",
   "metadata": {},
   "source": [
    "I imported the different libraries I would be using.\n",
    "\n",
    "Then I called in my _twitter API_ text files as _csv_ and assigned them to a variable called __bearer_token.__ \n",
    "\n",
    "    The bearer token is used to access the twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a493c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = pd.read_csv(\"twitterApp.txt\", header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c072392f",
   "metadata": {},
   "source": [
    "I isolated the Bearer Token from its label using _iloc_ then formated a line that included the header of Authorization and 'Bearer' followed by the token value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token['Bearer Token'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229ee169",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'Authorization' : 'Bearer {}'.format(bearer_token['Bearer Token'].iloc[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713fad2",
   "metadata": {},
   "source": [
    "I then set the endpoint url to a variable. This will allow me to use a query to search twitter for specified content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c63c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = 'https://api.twitter.com/2/tweets/search/recent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb3cdf",
   "metadata": {},
   "source": [
    "## Creating a Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d1121",
   "metadata": {},
   "source": [
    "Next I built my query and assigned it to a variable. The function _urllib.parse.quote_ takes the search that I put in quotes and replaces the symbols with _%xx_.\n",
    "        \n",
    "        The query I chose is ment to identify tweets with one or more of the hastags listed. I added #art AND #digitalart \n",
    "        rather than OR because in my experiece #art is used alot out of the context of what I am looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaadd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = urllib.parse.quote('( #art #digitalart OR #digitalart OR #traditionalart OR #myart OR #Inktober) lang:en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60883795",
   "metadata": {},
   "source": [
    "I created a variable to hold the tweet fields I wanted to get back from my query. Then I added my query to the end_point url defined earlier.\n",
    "\n",
    "        Author_id: provides the id of the __user__ who posted\n",
    "        id: provides the __tweet id__\n",
    "        text: provides the __text__ of the tweet\n",
    "        public_metrics: provides the __retweets, likes_count, reply_count,__ and __quote_count__.\n",
    "        created_at: proved the __date__ on which the post was made\n",
    "        \n",
    "I added __entities__ as well, which contains __hashtags__. This field will be useful when answering questions on how an artist is using twitter. For example, I could use this information to check if posts with the #digitalart got more reactions then #traditionalart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3c63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_fields = 'author_id,id,text,public_metrics,created_at,entities'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd54aa",
   "metadata": {},
   "source": [
    "I added the expansion \"author_id\" and added it to my query as _expansions_ containing \"username\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113eaec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansions = 'author_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a52277fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = endpoint_url + '?query={}&tweet.fields={}&expansions={}&user.fields={}&max_results=100'.format(query,tweet_fields,expansions,\"username\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835dcf2",
   "metadata": {},
   "source": [
    "## Creating Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f1531",
   "metadata": {},
   "source": [
    "Using __resquest__ from the _requests_ library i requested the data from the url I defined with headers and assigned that data to a variable.\n",
    "    I then used __loads__ from the _json_ library to create a ___dictionary___ out of the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c60d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = requests.request(\"GET\", url, headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c2347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1_dict = json.loads(response_1.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ed270",
   "metadata": {},
   "source": [
    "I created a __three dataframes__, one that held the original data, one that held the user data, and one that held the public metrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da011511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(response_1_dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd962d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = pd.DataFrame(response_1_dict['includes']['users'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1308d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(list(df['public_metrics']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751f95e",
   "metadata": {},
   "source": [
    "I then added the elements I wanted from each dictionary onto my primary dictionary. I did this with each of the separate \"pages\" of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5c24f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'] = user1['name']\n",
    "df['username'] = user1['username']\n",
    "df['likes'] = metrics['like_count']\n",
    "df['retweets'] = metrics['retweet_count']\n",
    "df['replys'] = metrics['reply_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1800b7c",
   "metadata": {},
   "source": [
    "Because Each dataset maxed out at 100, I had to access the next set or \"page\" of data. this is done with the _next_token_\n",
    "    in order to access this I identified the keys of the dictionary and used the 'next_token' key from the 'meta' key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b08bb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'includes', 'meta'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad3690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response_1_dict['meta']['next_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a6dea",
   "metadata": {},
   "source": [
    "To access the more data:\n",
    "\n",
    "    - I added the next token to my url and assigned it to a variable \n",
    "    - I then repeated the process above to create a new dictionary of data\n",
    "    - I repeated this process 2 more times to create 4 different dictionaries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c40aaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "page2 = url +'&next_token={}'.format(response_1_dict['meta']['next_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c87bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = requests.request(\"GET\",url = page2, headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19640413",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2_dict = json.loads(response_2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41761753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(response_2_dict['data'])\n",
    "user2 = pd.DataFrame(response_2_dict['includes']['users'])\n",
    "metrics2 = pd.DataFrame(list(df2['public_metrics']))\n",
    "ht2 = pd.DataFrame(list(df2['entities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a89570d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['name'] = user2['name']\n",
    "df2['username'] = user2['username']\n",
    "df2['likes'] = metrics2['like_count']\n",
    "df2['retweets'] = metrics2['retweet_count']\n",
    "df2['replys'] = metrics2['reply_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ffe49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "page3 = url +'&next_token={}'.format(response_2_dict['meta']['next_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "699cb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3 = requests.request(\"GET\",url = page3, headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52396dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3_dict = json.loads(response_3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b555ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(response_3_dict['data'])\n",
    "user3 = pd.DataFrame(response_3_dict['includes']['users'])\n",
    "metrics3 = pd.DataFrame(list(df3['public_metrics']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ea1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['name'] = user3['name']\n",
    "df3['username'] = user3['username']\n",
    "df3['likes'] = metrics3['like_count']\n",
    "df3['retweets'] = metrics3['retweet_count']\n",
    "df3['replys'] = metrics3['reply_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "173ab0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page4 = url +'&next_token={}'.format(response_3_dict['meta']['next_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58aeef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_4 = requests.request(\"GET\",url = page4, headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e76503b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_4_dict = json.loads(response_4.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44a0b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(response_4_dict['data'])\n",
    "user4 = pd.DataFrame(response_4_dict['includes']['users'])\n",
    "metrics4 = pd.DataFrame(list(df4['public_metrics']))\n",
    "ht4 = pd.DataFrame(list(df4['entities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cc6a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['name'] = user4['name']\n",
    "df4['username'] = user4['username']\n",
    "df4['likes'] = metrics4['like_count']\n",
    "df4['retweets'] = metrics4['retweet_count']\n",
    "df4['replys'] = metrics4['reply_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea8c3c",
   "metadata": {},
   "source": [
    "I __combined__ the four dictionaries together to create a _400 row_ dataframe by using the __DataFrame__ function from the _pandas library_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83570c",
   "metadata": {},
   "source": [
    "## Combining Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f7517d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.concat([df, df2, df3, df4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc822e",
   "metadata": {},
   "source": [
    "I delete the 'public_metrics' column from my master Data Frame to avoid duplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5b4480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweets['public_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0757c111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets.index) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2021a",
   "metadata": {},
   "source": [
    "I used the __concat__ function from the _pandas_ library to combine all my previous Data Frames and make one master data frame I called \"tweets\". \"tweets\" was 400 rows long.\n",
    "\n",
    "Then I used the __head__ and __tail__ functions to display the first and last 10 rows in my master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3f06e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>entities</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-20T03:37:30.000Z</td>\n",
       "      <td>1450667466196201473</td>\n",
       "      <td>{'urls': [{'start': 216, 'end': 239, 'url': 'h...</td>\n",
       "      <td>When it hits your cheeks and you feel it in th...</td>\n",
       "      <td>937347617658363904</td>\n",
       "      <td>Julius J Jervoso</td>\n",
       "      <td>ArtbyJoebalde</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-20T03:37:30.000Z</td>\n",
       "      <td>1450667466187677696</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 13, 'usernam...</td>\n",
       "      <td>RT @larapedan: Mother Night\\n#inktober #inktob...</td>\n",
       "      <td>2448621548</td>\n",
       "      <td>S A R R A H 🍥🔩🎀</td>\n",
       "      <td>SarrahPrinsesa</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-20T03:37:30.000Z</td>\n",
       "      <td>1450667463637491713</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 17, 'usernam...</td>\n",
       "      <td>RT @nanasibrushes: \"Lan Zhan, let's go back ho...</td>\n",
       "      <td>158554940</td>\n",
       "      <td>战해 🌻☀️</td>\n",
       "      <td>lmaoHae</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-20T03:37:27.000Z</td>\n",
       "      <td>1450667452438704128</td>\n",
       "      <td>{'urls': [{'start': 59, 'end': 82, 'url': 'htt...</td>\n",
       "      <td>Girls 👩🏻‍🤝‍👩🏼\\n#procreate \\n#digitalillustrati...</td>\n",
       "      <td>1447588345035452420</td>\n",
       "      <td>Suina 千千</td>\n",
       "      <td>fangsuinas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-20T03:37:27.000Z</td>\n",
       "      <td>1450667451457413120</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 19, 'usernam...</td>\n",
       "      <td>RT @eugenia_kelheor: Day 17 of Fantober with K...</td>\n",
       "      <td>1344895880558731266</td>\n",
       "      <td>🕸️| spooky month spooky sluts</td>\n",
       "      <td>mistalucilfer</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-10-20T03:37:26.000Z</td>\n",
       "      <td>1450667449263796225</td>\n",
       "      <td>{'urls': [{'start': 148, 'end': 171, 'url': 'h...</td>\n",
       "      <td>Couldn't figure out what to draw for today so ...</td>\n",
       "      <td>881304831276843009</td>\n",
       "      <td>Crapworks</td>\n",
       "      <td>crapworks1980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-10-20T03:37:24.000Z</td>\n",
       "      <td>1450667441047097345</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 10, 'usernam...</td>\n",
       "      <td>RT @Rafchu: Street Fighter rival schoolgirls K...</td>\n",
       "      <td>2852005678</td>\n",
       "      <td>Kyle Parker</td>\n",
       "      <td>Kylethemonkey24</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-10-20T03:37:18.000Z</td>\n",
       "      <td>1450667413523947520</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 15, 'usernam...</td>\n",
       "      <td>RT @judyhopps44: Oh, hello and on the fifteent...</td>\n",
       "      <td>397149313</td>\n",
       "      <td>Hisou</td>\n",
       "      <td>hisousihou</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-10-20T03:37:16.000Z</td>\n",
       "      <td>1450667405076844549</td>\n",
       "      <td>{'annotations': [{'start': 16, 'end': 44, 'pro...</td>\n",
       "      <td>RT @AFinnstark: Sekiro Vs The Demon of Hatred ...</td>\n",
       "      <td>1221195406706647040</td>\n",
       "      <td>Ruisu</td>\n",
       "      <td>RuisuTheFallen</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-10-20T03:37:14.000Z</td>\n",
       "      <td>1450667399779270658</td>\n",
       "      <td>{'annotations': [{'start': 36, 'end': 48, 'pro...</td>\n",
       "      <td>RT @Cubebrush: Depth sketching with Mental Can...</td>\n",
       "      <td>951066608889356288</td>\n",
       "      <td>Powdered Donut Bwushies~</td>\n",
       "      <td>bwushies</td>\n",
       "      <td>0</td>\n",
       "      <td>1029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0  2021-10-20T03:37:30.000Z  1450667466196201473   \n",
       "1  2021-10-20T03:37:30.000Z  1450667466187677696   \n",
       "2  2021-10-20T03:37:30.000Z  1450667463637491713   \n",
       "3  2021-10-20T03:37:27.000Z  1450667452438704128   \n",
       "4  2021-10-20T03:37:27.000Z  1450667451457413120   \n",
       "5  2021-10-20T03:37:26.000Z  1450667449263796225   \n",
       "6  2021-10-20T03:37:24.000Z  1450667441047097345   \n",
       "7  2021-10-20T03:37:18.000Z  1450667413523947520   \n",
       "8  2021-10-20T03:37:16.000Z  1450667405076844549   \n",
       "9  2021-10-20T03:37:14.000Z  1450667399779270658   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'urls': [{'start': 216, 'end': 239, 'url': 'h...   \n",
       "1  {'mentions': [{'start': 3, 'end': 13, 'usernam...   \n",
       "2  {'mentions': [{'start': 3, 'end': 17, 'usernam...   \n",
       "3  {'urls': [{'start': 59, 'end': 82, 'url': 'htt...   \n",
       "4  {'mentions': [{'start': 3, 'end': 19, 'usernam...   \n",
       "5  {'urls': [{'start': 148, 'end': 171, 'url': 'h...   \n",
       "6  {'mentions': [{'start': 3, 'end': 10, 'usernam...   \n",
       "7  {'mentions': [{'start': 3, 'end': 15, 'usernam...   \n",
       "8  {'annotations': [{'start': 16, 'end': 44, 'pro...   \n",
       "9  {'annotations': [{'start': 36, 'end': 48, 'pro...   \n",
       "\n",
       "                                                text            author_id  \\\n",
       "0  When it hits your cheeks and you feel it in th...   937347617658363904   \n",
       "1  RT @larapedan: Mother Night\\n#inktober #inktob...           2448621548   \n",
       "2  RT @nanasibrushes: \"Lan Zhan, let's go back ho...            158554940   \n",
       "3  Girls 👩🏻‍🤝‍👩🏼\\n#procreate \\n#digitalillustrati...  1447588345035452420   \n",
       "4  RT @eugenia_kelheor: Day 17 of Fantober with K...  1344895880558731266   \n",
       "5  Couldn't figure out what to draw for today so ...   881304831276843009   \n",
       "6  RT @Rafchu: Street Fighter rival schoolgirls K...           2852005678   \n",
       "7  RT @judyhopps44: Oh, hello and on the fifteent...            397149313   \n",
       "8  RT @AFinnstark: Sekiro Vs The Demon of Hatred ...  1221195406706647040   \n",
       "9  RT @Cubebrush: Depth sketching with Mental Can...   951066608889356288   \n",
       "\n",
       "                            name         username  likes  retweets  replys  \n",
       "0               Julius J Jervoso    ArtbyJoebalde      0         0       0  \n",
       "1                S A R R A H 🍥🔩🎀   SarrahPrinsesa      0        42       0  \n",
       "2                         战해 🌻☀️          lmaoHae      0        30       0  \n",
       "3                       Suina 千千       fangsuinas      0         0       0  \n",
       "4  🕸️| spooky month spooky sluts    mistalucilfer      0       127       0  \n",
       "5                      Crapworks    crapworks1980      0         0       0  \n",
       "6                    Kyle Parker  Kylethemonkey24      0       542       0  \n",
       "7                          Hisou       hisousihou      0        14       0  \n",
       "8                          Ruisu   RuisuTheFallen      0       464       0  \n",
       "9       Powdered Donut Bwushies~         bwushies      0      1029       0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "428841d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>entities</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2021-10-20T03:23:10.000Z</td>\n",
       "      <td>1450663859035983874</td>\n",
       "      <td>{'urls': [{'start': 179, 'end': 202, 'url': 'h...</td>\n",
       "      <td>My next Inktober drawing is called Star Phanto...</td>\n",
       "      <td>774385051282862080</td>\n",
       "      <td>artofjim</td>\n",
       "      <td>Art0fJim</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2021-10-20T03:23:10.000Z</td>\n",
       "      <td>1450663858947956736</td>\n",
       "      <td>{'hashtags': [{'start': 22, 'end': 32, 'tag': ...</td>\n",
       "      <td>RT @sayatale: Today's #monstober prompt: Corru...</td>\n",
       "      <td>897983798</td>\n",
       "      <td>雨宮ハルノフ</td>\n",
       "      <td>amamiyap9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2021-10-20T03:23:08.000Z</td>\n",
       "      <td>1450663849489678337</td>\n",
       "      <td>{'hashtags': [{'start': 85, 'end': 89, 'tag': ...</td>\n",
       "      <td>RT @BoredSourHeads: Been okay LFG washed up…ne...</td>\n",
       "      <td>1349639691428003843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2021-10-20T03:23:06.000Z</td>\n",
       "      <td>1450663840690184195</td>\n",
       "      <td>{'urls': [{'start': 135, 'end': 158, 'url': 'h...</td>\n",
       "      <td>I'm not proud of this one, but I wanted to get...</td>\n",
       "      <td>941534340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2021-10-20T03:23:03.000Z</td>\n",
       "      <td>1450663828727877633</td>\n",
       "      <td>{'hashtags': [{'start': 85, 'end': 89, 'tag': ...</td>\n",
       "      <td>RT @BoredSourHeads: Been okay LFG washed up…ne...</td>\n",
       "      <td>1349639691428003843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-10-20T03:23:00.000Z</td>\n",
       "      <td>1450663816795017219</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 19, 'usernam...</td>\n",
       "      <td>RT @dalmatian_guard: December Dalmatian.\\n\\nA ...</td>\n",
       "      <td>1340457607060852737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-10-20T03:23:00.000Z</td>\n",
       "      <td>1450663814488379392</td>\n",
       "      <td>{'hashtags': [{'start': 23, 'end': 32, 'tag': ...</td>\n",
       "      <td>RT @HatebitX: Day 9 of #inktober and I'm under...</td>\n",
       "      <td>1076494890081677313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-10-20T03:22:59.000Z</td>\n",
       "      <td>1450663811682234368</td>\n",
       "      <td>{'urls': [{'start': 115, 'end': 138, 'url': 'h...</td>\n",
       "      <td>Star Wars Inktober day 17: Collide\\ndope scene...</td>\n",
       "      <td>3086934937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2021-10-20T03:22:57.000Z</td>\n",
       "      <td>1450663802576375815</td>\n",
       "      <td>{'urls': [{'start': 87, 'end': 110, 'url': 'ht...</td>\n",
       "      <td>RT @Rafchu: Street Fighter rival schoolgirls K...</td>\n",
       "      <td>991532009913696257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021-10-20T03:22:55.000Z</td>\n",
       "      <td>1450663796557574145</td>\n",
       "      <td>{'hashtags': [{'start': 76, 'end': 80, 'tag': ...</td>\n",
       "      <td>RT @BoredSourHeads: Been okay LFG washed up…ne...</td>\n",
       "      <td>1349639691428003843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at                   id  \\\n",
       "90  2021-10-20T03:23:10.000Z  1450663859035983874   \n",
       "91  2021-10-20T03:23:10.000Z  1450663858947956736   \n",
       "92  2021-10-20T03:23:08.000Z  1450663849489678337   \n",
       "93  2021-10-20T03:23:06.000Z  1450663840690184195   \n",
       "94  2021-10-20T03:23:03.000Z  1450663828727877633   \n",
       "95  2021-10-20T03:23:00.000Z  1450663816795017219   \n",
       "96  2021-10-20T03:23:00.000Z  1450663814488379392   \n",
       "97  2021-10-20T03:22:59.000Z  1450663811682234368   \n",
       "98  2021-10-20T03:22:57.000Z  1450663802576375815   \n",
       "99  2021-10-20T03:22:55.000Z  1450663796557574145   \n",
       "\n",
       "                                             entities  \\\n",
       "90  {'urls': [{'start': 179, 'end': 202, 'url': 'h...   \n",
       "91  {'hashtags': [{'start': 22, 'end': 32, 'tag': ...   \n",
       "92  {'hashtags': [{'start': 85, 'end': 89, 'tag': ...   \n",
       "93  {'urls': [{'start': 135, 'end': 158, 'url': 'h...   \n",
       "94  {'hashtags': [{'start': 85, 'end': 89, 'tag': ...   \n",
       "95  {'mentions': [{'start': 3, 'end': 19, 'usernam...   \n",
       "96  {'hashtags': [{'start': 23, 'end': 32, 'tag': ...   \n",
       "97  {'urls': [{'start': 115, 'end': 138, 'url': 'h...   \n",
       "98  {'urls': [{'start': 87, 'end': 110, 'url': 'ht...   \n",
       "99  {'hashtags': [{'start': 76, 'end': 80, 'tag': ...   \n",
       "\n",
       "                                                 text            author_id  \\\n",
       "90  My next Inktober drawing is called Star Phanto...   774385051282862080   \n",
       "91  RT @sayatale: Today's #monstober prompt: Corru...            897983798   \n",
       "92  RT @BoredSourHeads: Been okay LFG washed up…ne...  1349639691428003843   \n",
       "93  I'm not proud of this one, but I wanted to get...            941534340   \n",
       "94  RT @BoredSourHeads: Been okay LFG washed up…ne...  1349639691428003843   \n",
       "95  RT @dalmatian_guard: December Dalmatian.\\n\\nA ...  1340457607060852737   \n",
       "96  RT @HatebitX: Day 9 of #inktober and I'm under...  1076494890081677313   \n",
       "97  Star Wars Inktober day 17: Collide\\ndope scene...           3086934937   \n",
       "98  RT @Rafchu: Street Fighter rival schoolgirls K...   991532009913696257   \n",
       "99  RT @BoredSourHeads: Been okay LFG washed up…ne...  1349639691428003843   \n",
       "\n",
       "        name   username  likes  retweets  replys  \n",
       "90  artofjim   Art0fJim      1         0       0  \n",
       "91    雨宮ハルノフ  amamiyap9      0         3       0  \n",
       "92       NaN        NaN      0         1       0  \n",
       "93       NaN        NaN      1         0       0  \n",
       "94       NaN        NaN      0         2       0  \n",
       "95       NaN        NaN      0         3       0  \n",
       "96       NaN        NaN      0         7       0  \n",
       "97       NaN        NaN      1         0       0  \n",
       "98       NaN        NaN      0       542       0  \n",
       "99       NaN        NaN      0         2       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ffc40b",
   "metadata": {},
   "source": [
    "I was satisfied with this data so I __exported__ my full data frame as a csv using the __to_csv__ function in python. \n",
    "\n",
    "I saved my data into the same folder as my jupyternotebook so that I may refer to it later when answering hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c33d54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(r'C:\\Users\\glori\\Data in EMAT\\tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f32c3",
   "metadata": {},
   "source": [
    "## Potential weaknesses:\n",
    "- This is only 400 tweets, in the grand scheme of things that is not much data. However it is enouph to give me some evidence to answer the questions I have. There are some issues with the data where it stands right now. For example, from _entities_ I only want _hashtag_ so I need to find a way to isolate that aspect and change the header to read __hashtags__. However the issue is that 'entities' is set as a string not a list, and I dont have the knowledge yet to parse it into a list. \n",
    "\n",
    "- It should also be noted that the like_count appears to be 0 for all the columns. This is most likely inacurate. For example a tweet with over 2000 retweets, such as the one on line 98, would most likely NOT hav 0 likes.\n",
    "\n",
    "- there is a lot of duplicate code. It would be beneficial  to create a function that created each of the individual data frames so that I could simply add in a couple variables and cut down on the lines of code.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In order to have the best results for my hypothesis I would need to:\n",
    "1. Retrieve the 'tag' value from the _entities_ column\n",
    "2. find a way to retrieve accurate \"like\" counts\n",
    "3. Understand why some of the values are listed as NaN\n",
    "4. create a function to combine and create the different \"pages\" of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
